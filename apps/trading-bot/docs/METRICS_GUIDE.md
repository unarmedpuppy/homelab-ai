# Metrics & Observability Guide

**Last Updated**: December 19, 2024  
**Status**: Active Documentation

---

## Overview

This guide explains how to use and monitor metrics in the trading bot system. The system uses Prometheus for metrics collection and provides comprehensive instrumentation for all critical operations.

## Quick Start

### Accessing Metrics

Metrics are exposed at the `/metrics` endpoint in Prometheus format:

```bash
# Get all metrics
curl http://localhost:8000/metrics

# Using requests in Python
import requests
response = requests.get('http://localhost:8000/metrics')
print(response.text)
```

### Available Metrics

The system tracks metrics across several categories:

1. **API Request Metrics** - HTTP endpoint performance
2. **Trading Metrics** - Trade execution and performance
3. **Strategy Metrics** - Strategy evaluation and signals
4. **Data Provider Metrics** - API call performance and reliability
5. **Sentiment Metrics** - Sentiment calculation and provider usage
6. **System Health Metrics** - Resource usage and performance

---

## Metric Types

### Counter

Counters track the total number of events. They only increase (or reset to zero on restart).

**Example**: `http_requests_total`

```promql
# Request rate (requests per second)
rate(http_requests_total[5m])

# Total requests in last hour
increase(http_requests_total[1h])
```

### Histogram

Histograms track the distribution of values, typically durations or sizes.

**Example**: `http_request_duration_seconds`

```promql
# Average request duration
rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])

# 95th percentile duration
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
```

### Gauge

Gauges track values that can go up or down (like current memory usage).

**Example**: `memory_usage_bytes`

```promql
# Current memory usage
memory_usage_bytes

# Average memory usage over time
avg_over_time(memory_usage_bytes[5m])
```

---

## Key Metrics Reference

### API Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `http_requests_total` | Counter | Total HTTP requests by endpoint, method, status |
| `http_request_duration_seconds` | Histogram | Request duration distribution |
| `http_request_size_bytes` | Histogram | Request payload sizes |
| `http_response_size_bytes` | Histogram | Response payload sizes |

### Trading Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `trades_executed_total` | Counter | Total trades executed by strategy, symbol |
| `trade_execution_duration_seconds` | Histogram | Trade execution time |
| `trade_profit_loss` | Histogram | Profit/loss per trade |
| `positions_open` | Gauge | Currently open positions |

### Strategy Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `strategy_evaluations_total` | Counter | Strategy evaluations by strategy |
| `strategy_evaluation_duration_seconds` | Histogram | Evaluation time |
| `strategy_signals_generated_total` | Counter | Signals generated by strategy, type |
| `strategy_signal_confidence` | Histogram | Signal confidence scores |

### Sentiment Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `sentiment_calculation_duration_seconds` | Histogram | Sentiment calculation time |
| `sentiment_calculations_total` | Counter | Total calculations by result (success, failed, cached) |
| `sentiment_provider_usage_total` | Counter | Provider usage by provider, symbol, status |
| `sentiment_score_distribution` | Histogram | Distribution of sentiment scores |
| `sentiment_divergence_detected_total` | Counter | Divergence detections by severity |

### Data Provider Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `data_provider_requests_total` | Counter | API requests by provider, endpoint |
| `data_provider_response_time_seconds` | Histogram | Response times |
| `data_provider_errors_total` | Counter | Errors by provider, error type |
| `data_provider_cache_hits_total` | Counter | Cache hits by provider |

### System Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `system_memory_usage_bytes` | Gauge | Memory usage |
| `system_cpu_usage_percent` | Gauge | CPU usage percentage |
| `system_uptime_seconds` | Gauge | System uptime |
| `database_query_duration_seconds` | Histogram | Database query times |

---

## Using Metrics in Code

### Creating Metrics

```python
from src.utils.metrics import (
    get_or_create_counter,
    get_or_create_histogram,
    get_or_create_gauge
)

# Create a counter
counter = get_or_create_counter(
    'my_operation_total',
    'Total number of operations',
    labelnames=['operation_type']
)

# Increment counter
counter.labels(operation_type='create').inc()
counter.labels(operation_type='update').inc(5)

# Create a histogram
histogram = get_or_create_histogram(
    'my_operation_duration_seconds',
    'Operation duration',
    labelnames=['operation_type'],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0]
)

# Record duration
histogram.labels(operation_type='create').observe(0.25)

# Create a gauge
gauge = get_or_create_gauge(
    'my_resource_usage',
    'Current resource usage',
    labelnames=['resource_type']
)

# Set gauge value
gauge.labels(resource_type='cpu').set(75.5)

# Increment/decrement
gauge.labels(resource_type='memory').inc(10)
gauge.labels(resource_type='memory').dec(5)
```

### Using Decorators

```python
from src.utils.metrics import track_duration, track_call_count

# Track function duration
@track_duration('my_function_duration_seconds', 'My function duration', ['param'])
def my_function(param):
    # Function logic
    pass

# Track function call count
@track_call_count('my_function_calls_total', 'My function calls', ['param'])
def my_function(param):
    # Function logic
    pass
```

### Using Context Managers

```python
from src.utils.metrics import track_duration_context

# Track code block duration
with track_duration_context(
    'my_operation_duration_seconds',
    'Operation duration',
    labels={'operation': 'process_data'}
):
    # Code to measure
    process_data()
```

---

## Prometheus Queries

### Common Queries

```promql
# Request rate over last 5 minutes
rate(http_requests_total[5m])

# Error rate percentage
rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100

# 95th percentile request duration
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# Average sentiment calculation time
rate(sentiment_calculation_duration_seconds_sum[5m]) / rate(sentiment_calculation_duration_seconds_count[5m])

# Provider usage by provider
sum by (provider) (rate(sentiment_provider_usage_total[5m]))

# Cache hit rate
rate(data_provider_cache_hits_total[5m]) / rate(data_provider_requests_total[5m]) * 100
```

### Alerts

```promql
# High error rate alert
rate(http_requests_total{status=~"5.."}[5m]) > 0.1

# Slow requests alert
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2

# High CPU usage alert
system_cpu_usage_percent > 90

# High memory usage alert
system_memory_usage_bytes / 1024 / 1024 / 1024 > 8  # > 8GB
```

---

## Grafana Dashboards

See `docs/GRAFANA_DASHBOARDS.md` for dashboard configuration and examples.

### Recommended Dashboards

1. **System Overview** - Overall system health
2. **API Performance** - Request rates, durations, error rates
3. **Trading Performance** - Trade execution, P&L, positions
4. **Strategy Performance** - Strategy evaluations, signals
5. **Sentiment Analytics** - Sentiment calculations, provider usage
6. **Data Provider Health** - Provider reliability, cache performance

---

## Configuration

### Prometheus Configuration

Add to your `prometheus.yml`:

```yaml
scrape_configs:
  - job_name: 'trading-bot'
    scrape_interval: 15s
    static_configs:
      - targets: ['localhost:8000']
```

### Environment Variables

```bash
# Enable/disable metrics collection (default: enabled)
METRICS_ENABLED=true

# Metrics endpoint path (default: /metrics)
METRICS_ENDPOINT=/metrics
```

---

## Troubleshooting

### Metrics Not Appearing

1. **Check endpoint**: Verify `/metrics` endpoint is accessible
2. **Check Prometheus**: Ensure Prometheus is scraping the endpoint
3. **Check labels**: Verify label names match between metric creation and queries
4. **Check registry**: Ensure metrics are registered in the global registry

### High Cardinality

Avoid high-cardinality labels (like user IDs, timestamps):

```python
# ❌ BAD - High cardinality
counter.labels(user_id=str(user.id)).inc()

# ✅ GOOD - Low cardinality
counter.labels(user_type='premium' if user.premium else 'standard').inc()
```

### Performance Impact

Metrics collection has minimal overhead:
- Counters: < 0.1ms per increment
- Histograms: < 0.2ms per observation
- Gauges: < 0.1ms per set/update

Total overhead is typically < 1% of request processing time.

---

## Best Practices

1. **Use Descriptive Names**: Follow Prometheus naming conventions
   - Use `_total` suffix for counters
   - Use `_seconds`, `_bytes`, etc. for units
   - Use snake_case

2. **Label Carefully**: Keep label cardinality low
   - Use fixed sets of values (not dynamic IDs)
   - Limit to 5-10 labels per metric

3. **Document Metrics**: Add clear descriptions
   ```python
   counter = get_or_create_counter(
       'trades_executed_total',
       'Total number of trades executed (both successful and failed)',  # Clear description
       labelnames=['strategy', 'symbol']
   )
   ```

4. **Monitor Metrics**: Set up alerts for critical metrics
   - Error rates
   - Latency percentiles
   - Resource usage

5. **Test Metrics**: Include metrics in tests
   - Verify metrics are created
   - Verify metrics are updated
   - Verify metrics are accessible

---

## Additional Resources

- [Prometheus Documentation](https://prometheus.io/docs/)
- [PromQL Guide](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [Metric Best Practices](https://prometheus.io/docs/practices/naming/)

---

## Support

For questions or issues:
1. Check this guide
2. Review metric definitions in code
3. Check Prometheus/Grafana logs
4. Review test files for examples

